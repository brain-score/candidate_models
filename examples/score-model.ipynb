{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow (-Slim)\n",
    "First, define your model (its endpoints) and its preprocessing function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /braintree/home/msch/miniconda3/envs/candidate-models/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:118: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "from model_tools.activations.tensorflow import load_resize_image\n",
    "import tensorflow as tf\n",
    "slim = tf.contrib.slim\n",
    "tf.reset_default_graph()\n",
    "\n",
    "image_size = 224\n",
    "placeholder = tf.placeholder(dtype=tf.string, shape=[64])\n",
    "preprocess = lambda image_path: load_resize_image(image_path, image_size)\n",
    "preprocess = tf.map_fn(preprocess, placeholder, dtype=tf.float32)\n",
    "\n",
    "with tf.variable_scope('my_model', values=[preprocess]) as sc:\n",
    "    end_points_collection = sc.original_name_scope + '_end_points'\n",
    "    # Collect outputs for conv2d, fully_connected and max_pool2d.\n",
    "    with slim.arg_scope([slim.conv2d, slim.fully_connected, slim.max_pool2d],\n",
    "                        outputs_collections=[end_points_collection]):\n",
    "        net = slim.conv2d(preprocess, 64, [11, 11], 4, padding='VALID', scope='conv1')\n",
    "        net = slim.max_pool2d(net, [5, 5], 5, scope='pool1')\n",
    "        net = slim.max_pool2d(net, [3, 3], 2, scope='pool2')\n",
    "        net = slim.flatten(net, scope='flatten')\n",
    "        net = slim.fully_connected(net, 1000, scope='logits')\n",
    "        endpoints = slim.utils.convert_collection_to_dict(end_points_collection)\n",
    "\n",
    "session = tf.Session()\n",
    "session.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, using the TensorflowSlimWrapper, convert your model into an activations model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_tools.activations.tensorflow import TensorflowSlimWrapper\n",
    "\n",
    "activations_model = TensorflowSlimWrapper(identifier='tf-custom', labels_offset=0,\n",
    "                                          endpoints=endpoints, inputs=placeholder, session=session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model candidates in Brain-Score have to follow the [model_interface](https://github.com/brain-score/brain-score/blob/master/brainscore/model_interface.py).\n",
    "One of the major steps for most ML models to map onto the brain model interface is deciding what layers map onto cortical regions.\n",
    "If you know which layer corresponds to which region beforehand, you can just use a `LayerModel` and `commit` a layer to a region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "activations: 100%|██████████| 2560/2560 [00:05<00:00, 550.08it/s]\n",
      "cross-validation: 100%|██████████| 10/10 [00:39<00:00,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Score (aggregation: 2)>\n",
      "array([ 0.494012, 10.52275 ])\n",
      "Coordinates:\n",
      "  * aggregation  (aggregation) <U6 'center' 'error'\n",
      "Attributes:\n",
      "    raw:      <xarray.Score (aggregation: 2)>\\narray([0.405688, 0.005272])\\nC...\n",
      "    ceiling:  <xarray.Score (aggregation: 2)>\\narray([8.212101e-01, 5.010154e...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from candidate_models import score_model\n",
    "from model_tools.brain_transformation import LayerMappedModel\n",
    "\n",
    "model = LayerMappedModel(\"tf-custom-pool2\", activations_model=activations_model)\n",
    "model.commit(\"IT\", \"my_model/pool2\")\n",
    "\n",
    "score = score_model(model_identifier=model.identifier, model=model,\n",
    "                    benchmark_identifier='dicarlo.Majaj2015.IT-regressing')\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also empirically choose the best layer for a particular region. You might want to use PCA for large layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using layer my_model/pool2 for IT\n",
      "<xarray.Score (aggregation: 2)>\n",
      "array([ 0.494012, 10.52275 ])\n",
      "Coordinates:\n",
      "  * aggregation  (aggregation) <U6 'center' 'error'\n",
      "Attributes:\n",
      "    raw:      <xarray.Score (aggregation: 2)>\\narray([0.405688, 0.005272])\\nC...\n",
      "    ceiling:  <xarray.Score (aggregation: 2)>\\narray([8.212101e-01, 5.010154e...\n"
     ]
    }
   ],
   "source": [
    "from model_tools.brain_transformation import LayerSelection\n",
    "from model_tools.activations.pca import LayerPCA\n",
    "from brainscore.assemblies.private import load_assembly\n",
    "\n",
    "assembly = load_assembly('dicarlo.Majaj2015.lowvar.IT', average_repetition=False)\n",
    "layer_selection = LayerSelection(model_identifier=model.identifier, activations_model=activations_model, \n",
    "                                 layers=['my_model/conv1', 'my_model/pool1', 'my_model/pool2'])\n",
    "LayerPCA.hook(activations_model, n_components=1000)\n",
    "best_layer = layer_selection(assembly)\n",
    "print(f'Using layer {best_layer} for IT')\n",
    "\n",
    "model = LayerMappedModel(model.identifier, activations_model=activations_model)\n",
    "model.commit('IT', best_layer)\n",
    "\n",
    "score = score_model(model_identifier=model.identifier, model=model,\n",
    "                    benchmark_identifier='dicarlo.Majaj2015.IT-regressing')\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, you can resize stimuli according to visual degree angle like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<model_tools.activations.core.HookHandle at 0x7efd31c30390>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model_tools.brain_transformation import PixelsToDegrees\n",
    "\n",
    "PixelsToDegrees.hook(activations_model, target_pixels=224)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of these steps are sample implementations and as long as you implement the model_interface,\n",
    "it does not matter how you get there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-defined models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scoring a model on neural data can be done in a single line using the `score_model` method and the `brain_translated_pool`.\n",
    "Pre-defined layers of a model will be used to retrieve the activations.\n",
    "Just like with the model implementations, the result of this method call will be cached \n",
    "so that it only needs to be computed once.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Score (aggregation: 2)>\n",
      "array([0.69516 , 4.740383])\n",
      "Coordinates:\n",
      "  * aggregation  (aggregation) <U6 'center' 'error'\n",
      "Attributes:\n",
      "    raw:      <xarray.Score (aggregation: 2)>\\narray([0.570873, 0.002375])\\nC...\n",
      "    ceiling:  <xarray.Score (aggregation: 2)>\\narray([8.212101e-01, 5.010154e...\n"
     ]
    }
   ],
   "source": [
    "from candidate_models import score_model\n",
    "from candidate_models.model_commitments import brain_translated_pool\n",
    "\n",
    "identifier = 'alexnet-pca_1000-degrees'\n",
    "model = brain_translated_pool[identifier]\n",
    "score = score_model(model_identifier=identifier, model=model, benchmark_identifier='dicarlo.Majaj2015.IT-regressing')\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score aggregate and raw values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A score typically comes with an estimate of the center (e.g. mean) and error (e.g. standard error of the mean).\n",
    "These values are aggregations over splits and often neuroids.\n",
    "\n",
    "We can also retrieve the raw scores from the same object, using `.raw` or `.attrs['raw']`.\n",
    "The raw scores are for instance individual neuroids and splits.\n",
    "In this case, we access raw twice: 1) to remove the ceiling, and 2) to remove the aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataAssembly (split: 10, neuroid: 168)>\n",
      "array([[0.332988, 0.534487, 0.523227, ..., 0.662326, 0.708434, 0.689082],\n",
      "       [0.355074, 0.510973, 0.445392, ..., 0.741481, 0.663006, 0.719654],\n",
      "       [0.351747, 0.588668, 0.449489, ..., 0.716738, 0.764242, 0.744131],\n",
      "       ...,\n",
      "       [0.301904, 0.514429, 0.399632, ..., 0.716352, 0.695416, 0.70639 ],\n",
      "       [0.245484, 0.48177 , 0.520564, ..., 0.721901, 0.715378, 0.725057],\n",
      "       [0.315608, 0.537013, 0.54319 , ..., 0.751   , 0.718046, 0.715887]])\n",
      "Coordinates:\n",
      "  * split       (split) int64 0 1 2 3 4 5 6 7 8 9\n",
      "  * neuroid     (neuroid) MultiIndex\n",
      "  - neuroid_id  (neuroid) object 'Chabo_L_A_2_4' 'Chabo_L_A_3_3' ...\n",
      "  - arr         (neuroid) object 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' ...\n",
      "  - col         (neuroid) int64 4 3 5 0 1 2 3 4 5 6 2 3 5 0 1 2 3 4 5 6 1 2 ...\n",
      "  - hemisphere  (neuroid) object 'L' 'L' 'L' 'L' 'L' 'L' 'L' 'L' 'L' 'L' 'L' ...\n",
      "  - subregion   (neuroid) object 'cIT' 'cIT' 'aIT' 'cIT' 'cIT' 'cIT' 'cIT' ...\n",
      "  - animal      (neuroid) object 'Chabo' 'Chabo' 'Chabo' 'Chabo' 'Chabo' ...\n",
      "  - y           (neuroid) float64 -1.0 -0.6 -0.6 -0.2 -0.2 -0.2 -0.2 -0.2 ...\n",
      "  - x           (neuroid) float64 -0.2 -0.6 0.2 -1.8 -1.4 -1.0 -0.6 -0.2 0.2 ...\n",
      "  - row         (neuroid) int64 2 3 3 4 4 4 4 4 4 4 5 5 5 6 6 6 6 6 6 6 7 7 ...\n",
      "  - region      (neuroid) object 'IT' 'IT' 'IT' 'IT' 'IT' 'IT' 'IT' 'IT' ...\n"
     ]
    }
   ],
   "source": [
    "raw = score.raw.raw\n",
    "print(raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raw values are just another xarray object and as such, we can easily filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataAssembly (split: 10, neuroid: 75)>\n",
      "array([[0.332988, 0.534487, 0.326301, ..., 0.416322, 0.752089, 0.568259],\n",
      "       [0.355074, 0.510973, 0.334426, ..., 0.418433, 0.669294, 0.552998],\n",
      "       [0.351747, 0.588668, 0.2921  , ..., 0.329157, 0.722749, 0.548502],\n",
      "       ...,\n",
      "       [0.301904, 0.514429, 0.232041, ..., 0.338111, 0.70119 , 0.599551],\n",
      "       [0.245484, 0.48177 , 0.291308, ..., 0.356857, 0.704378, 0.477234],\n",
      "       [0.315608, 0.537013, 0.364099, ..., 0.335651, 0.728882, 0.526765]])\n",
      "Coordinates:\n",
      "  * split       (split) int64 0 1 2 3 4 5 6 7 8 9\n",
      "  * neuroid     (neuroid) MultiIndex\n",
      "  - neuroid_id  (neuroid) object 'Chabo_L_A_2_4' 'Chabo_L_A_3_3' ...\n",
      "  - arr         (neuroid) object 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' ...\n",
      "  - col         (neuroid) int64 4 3 0 1 2 3 4 2 3 0 1 2 3 4 1 2 3 4 2 3 4 3 ...\n",
      "  - hemisphere  (neuroid) object 'L' 'L' 'L' 'L' 'L' 'L' 'L' 'L' 'L' 'L' 'L' ...\n",
      "  - animal      (neuroid) object 'Chabo' 'Chabo' 'Chabo' 'Chabo' 'Chabo' ...\n",
      "  - y           (neuroid) float64 -1.0 -0.6 -0.2 -0.2 -0.2 -0.2 -0.2 0.2 0.2 ...\n",
      "  - x           (neuroid) float64 -0.2 -0.6 -1.8 -1.4 -1.0 -0.6 -0.2 -1.0 ...\n",
      "  - row         (neuroid) int64 2 3 4 4 4 4 4 5 5 6 6 6 6 6 7 7 7 7 8 8 8 9 ...\n",
      "  - region      (neuroid) object 'IT' 'IT' 'IT' 'IT' 'IT' 'IT' 'IT' 'IT' ...\n"
     ]
    }
   ],
   "source": [
    "print(raw.sel(subregion='cIT'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
