{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow (-Slim)\n",
    "First, define your model (its endpoints) and its preprocessing function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /braintree/home/msch/miniconda3/envs/candidate-models/lib/python3.6/site-packages/tensorflow/python/ops/tensor_array_ops.py:162: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /braintree/home/msch/miniconda3/envs/candidate-models/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/layers.py:1624: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /braintree/home/msch/miniconda3/envs/candidate-models/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:193: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "from model_tools.activations.tensorflow import load_resize_image\n",
    "import tensorflow as tf\n",
    "slim = tf.contrib.slim\n",
    "tf.reset_default_graph()\n",
    "\n",
    "image_size = 224\n",
    "placeholder = tf.placeholder(dtype=tf.string, shape=[64])\n",
    "preprocess = lambda image_path: load_resize_image(image_path, image_size)\n",
    "preprocess = tf.map_fn(preprocess, placeholder, dtype=tf.float32)\n",
    "\n",
    "with tf.variable_scope('my_model', values=[preprocess]) as sc:\n",
    "    end_points_collection = sc.original_name_scope + '_end_points'\n",
    "    # Collect outputs for conv2d, fully_connected and max_pool2d.\n",
    "    with slim.arg_scope([slim.conv2d, slim.fully_connected, slim.max_pool2d],\n",
    "                        outputs_collections=[end_points_collection]):\n",
    "        net = slim.conv2d(preprocess, 64, [11, 11], 4, padding='VALID', scope='conv1')\n",
    "        net = slim.max_pool2d(net, [5, 5], 5, scope='pool1')\n",
    "        net = slim.max_pool2d(net, [3, 3], 2, scope='pool2')\n",
    "        net = slim.flatten(net, scope='flatten')\n",
    "        net = slim.fully_connected(net, 1000, scope='logits')\n",
    "        endpoints = slim.utils.convert_collection_to_dict(end_points_collection)\n",
    "\n",
    "session = tf.Session()\n",
    "session.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, using the TensorflowSlimWrapper, convert your model into an activations model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_tools.activations.tensorflow import TensorflowSlimWrapper\n",
    "\n",
    "activations_model = TensorflowSlimWrapper(identifier='tf-custom', labels_offset=0,\n",
    "                                          endpoints=endpoints, inputs=placeholder, session=session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model candidates in Brain-Score have to follow the [model_interface](https://github.com/brain-score/brain-score/blob/master/brainscore/model_interface.py).\n",
    "The main step for most ML models to map onto the brain model interface is deciding what layers map onto cortical regions.\n",
    "If you know which layer corresponds to which region beforehand, you can just use a `LayerMappedModel` and `commit` a layer to a region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "activations: 100%|██████████| 2560/2560 [00:03<00:00, 675.03it/s]\n",
      "layer packaging: 100%|██████████| 1/1 [00:00<00:00, 63.91it/s]\n",
      "cross-validation: 100%|██████████| 10/10 [00:31<00:00,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Score (aggregation: 2)>\n",
      "array([0.230105, 0.007537])\n",
      "Coordinates:\n",
      "  * aggregation  (aggregation) <U6 'center' 'error'\n",
      "Attributes:\n",
      "    raw:                   <xarray.Score (aggregation: 2)>\\narray([0.394231, ...\n",
      "    ceiling:               <xarray.Score (aggregation: 2)>\\narray([8.218406e-...\n",
      "    model_identifier:      tf-custom-pool2\n",
      "    benchmark_identifier:  dicarlo.Majaj2015.IT-pls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from candidate_models import score_model\n",
    "from model_tools.brain_transformation import LayerMappedModel, TemporalIgnore\n",
    "\n",
    "# layer -> region\n",
    "model = LayerMappedModel(\"tf-custom-pool2\", activations_model=activations_model)\n",
    "model.commit(\"IT\", \"my_model/pool2\")\n",
    "# ignore time_bins\n",
    "model = TemporalIgnore(model)\n",
    "\n",
    "score = score_model(model_identifier=model.identifier, model=model,\n",
    "                    benchmark_identifier='dicarlo.Majaj2015.IT-pls')\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also empirically choose the best layer for a particular region. You might want to use PCA for large layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "activations:   0%|          | 0/3200 [00:00<?, ?it/s]\n",
      "activations:   0%|          | 0/1024 [00:00<?, ?it/s]\u001b[A\n",
      "activations:   6%|▋         | 64/1024 [00:00<00:01, 496.97it/s]\u001b[A\n",
      "activations:  12%|█▎        | 128/1024 [00:00<00:02, 413.92it/s]\u001b[A\n",
      "activations:  19%|█▉        | 192/1024 [00:00<00:02, 353.48it/s]\u001b[A\n",
      "activations:  25%|██▌       | 256/1024 [00:00<00:02, 304.87it/s]\u001b[A\n",
      "activations:  31%|███▏      | 320/1024 [00:01<00:02, 261.93it/s]\u001b[A\n",
      "activations:  38%|███▊      | 384/1024 [00:01<00:02, 230.98it/s]\u001b[A\n",
      "activations:  44%|████▍     | 448/1024 [00:01<00:02, 204.42it/s]\u001b[A\n",
      "activations:  50%|█████     | 512/1024 [00:02<00:02, 185.53it/s]\u001b[A\n",
      "activations:  56%|█████▋    | 576/1024 [00:02<00:02, 162.60it/s]\u001b[A\n",
      "activations:  62%|██████▎   | 640/1024 [00:03<00:02, 148.82it/s]\u001b[A\n",
      "activations:  69%|██████▉   | 704/1024 [00:03<00:02, 136.74it/s]\u001b[A\n",
      "activations:  75%|███████▌  | 768/1024 [00:04<00:02, 123.18it/s]\u001b[A\n",
      "activations:  81%|████████▏ | 832/1024 [00:05<00:01, 112.83it/s]\u001b[A\n",
      "activations:  88%|████████▊ | 896/1024 [00:05<00:01, 107.25it/s]\u001b[A\n",
      "activations:  94%|█████████▍| 960/1024 [00:06<00:00, 96.35it/s] \u001b[A\n",
      "activations: 100%|██████████| 1024/1024 [00:07<00:00, 93.09it/s]\u001b[A\n",
      "layer packaging:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "layer packaging:  33%|███▎      | 1/3 [00:00<00:01,  1.01it/s]\u001b[A\n",
      "layer packaging: 100%|██████████| 3/3 [00:01<00:00,  2.78it/s]\u001b[A\n",
      "layer principal components:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "layer principal components:  33%|███▎      | 1/3 [00:00<00:01,  1.60it/s]\u001b[A\n",
      "layer principal components:  67%|██████▋   | 2/3 [00:02<00:01,  1.09s/it]\u001b[A\n",
      "activations: 100%|██████████| 3200/3200 [02:09<00:00, 71.41it/s] .81s/it]\u001b[A\n",
      "layer packaging: 100%|██████████| 3/3 [00:00<00:00, 50.11it/s]\n",
      "layers:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "cross-validation:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "cross-validation:  10%|█         | 1/10 [00:03<00:31,  3.48s/it]\u001b[A\n",
      "cross-validation:  20%|██        | 2/10 [00:06<00:27,  3.42s/it]\u001b[A\n",
      "cross-validation:  30%|███       | 3/10 [00:10<00:24,  3.49s/it]\u001b[A\n",
      "cross-validation:  40%|████      | 4/10 [00:13<00:21,  3.50s/it]\u001b[A\n",
      "cross-validation:  50%|█████     | 5/10 [00:17<00:16,  3.38s/it]\u001b[A\n",
      "cross-validation:  60%|██████    | 6/10 [00:20<00:13,  3.41s/it]\u001b[A\n",
      "cross-validation:  70%|███████   | 7/10 [00:24<00:10,  3.51s/it]\u001b[A\n",
      "cross-validation:  80%|████████  | 8/10 [00:27<00:06,  3.45s/it]\u001b[A\n",
      "cross-validation:  90%|█████████ | 9/10 [00:30<00:03,  3.35s/it]\u001b[A\n",
      "layers:  33%|███▎      | 1/3 [00:34<01:09, 34.53s/it],  3.34s/it]\u001b[A\n",
      "cross-validation:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "cross-validation:  10%|█         | 1/10 [00:03<00:32,  3.63s/it]\u001b[A\n",
      "cross-validation:  20%|██        | 2/10 [00:07<00:28,  3.62s/it]\u001b[A\n",
      "cross-validation:  30%|███       | 3/10 [00:10<00:24,  3.56s/it]\u001b[A\n",
      "cross-validation:  40%|████      | 4/10 [00:14<00:21,  3.54s/it]\u001b[A\n",
      "cross-validation:  50%|█████     | 5/10 [00:17<00:17,  3.52s/it]\u001b[A\n",
      "cross-validation:  60%|██████    | 6/10 [00:21<00:13,  3.49s/it]\u001b[A\n",
      "cross-validation:  70%|███████   | 7/10 [00:24<00:10,  3.45s/it]\u001b[A\n",
      "cross-validation:  80%|████████  | 8/10 [00:28<00:07,  3.52s/it]\u001b[A\n",
      "cross-validation:  90%|█████████ | 9/10 [00:31<00:03,  3.49s/it]\u001b[A\n",
      "layers:  67%|██████▋   | 2/3 [01:10<00:34, 34.88s/it],  3.59s/it]\u001b[A\n",
      "cross-validation:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "cross-validation:  10%|█         | 1/10 [00:03<00:33,  3.74s/it]\u001b[A\n",
      "cross-validation:  20%|██        | 2/10 [00:08<00:31,  3.90s/it]\u001b[A\n",
      "cross-validation:  30%|███       | 3/10 [00:11<00:27,  3.87s/it]\u001b[A\n",
      "cross-validation:  40%|████      | 4/10 [00:15<00:23,  3.84s/it]\u001b[A\n",
      "cross-validation:  50%|█████     | 5/10 [00:18<00:18,  3.69s/it]\u001b[A\n",
      "cross-validation:  60%|██████    | 6/10 [00:22<00:14,  3.65s/it]\u001b[A\n",
      "cross-validation:  70%|███████   | 7/10 [00:26<00:10,  3.62s/it]\u001b[A\n",
      "cross-validation:  80%|████████  | 8/10 [00:29<00:07,  3.62s/it]\u001b[A\n",
      "cross-validation:  90%|█████████ | 9/10 [00:32<00:03,  3.52s/it]\u001b[A\n",
      "layers: 100%|██████████| 3/3 [01:47<00:00, 35.62s/it],  3.67s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using layer my_model/pool2 for IT\n",
      "<xarray.Score (aggregation: 2)>\n",
      "array([0.230105, 0.007537])\n",
      "Coordinates:\n",
      "  * aggregation  (aggregation) <U6 'center' 'error'\n",
      "Attributes:\n",
      "    raw:                   <xarray.Score (aggregation: 2)>\\narray([0.394231, ...\n",
      "    ceiling:               <xarray.Score (aggregation: 2)>\\narray([8.218406e-...\n",
      "    model_identifier:      tf-custom-pool2\n",
      "    benchmark_identifier:  dicarlo.Majaj2015.IT-pls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from model_tools.brain_transformation import LayerSelection\n",
    "from model_tools.activations.pca import LayerPCA\n",
    "from brainscore.assemblies.public import load_assembly\n",
    "\n",
    "# select best layer based on separate data\n",
    "assembly = load_assembly('dicarlo.Majaj2015.lowvar.IT', average_repetition=False)\n",
    "layer_selection = LayerSelection(model_identifier=model.identifier, activations_model=activations_model, \n",
    "                                 layers=['my_model/conv1', 'my_model/pool1', 'my_model/pool2'])\n",
    "LayerPCA.hook(activations_model, n_components=1000)\n",
    "best_layer = layer_selection(assembly)\n",
    "print(f'Using layer {best_layer} for IT')\n",
    "\n",
    "# commit best layer\n",
    "model = LayerMappedModel(model.identifier, activations_model=activations_model)\n",
    "model.commit('IT', best_layer)\n",
    "\n",
    "# evaluate committed model\n",
    "score = score_model(model_identifier=model.identifier, model=model,\n",
    "                    benchmark_identifier='dicarlo.Majaj2015.IT-pls')\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of these steps are sample implementations and as long as you implement the model_interface,\n",
    "it does not matter how you get there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-defined models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scoring a model on neural data can be done in a single line using the `score_model` method and the `brain_translated_pool`.\n",
    "Pre-defined layers of a model will be used to retrieve the activations.\n",
    "Just like with the model implementations, the result of this method call will be cached \n",
    "so that it only needs to be computed once.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Score (aggregation: 2)>\n",
      "array([0.725285, 5.613512])\n",
      "Coordinates:\n",
      "  * aggregation  (aggregation) <U6 'center' 'error'\n",
      "Attributes:\n",
      "    raw:      <xarray.Score (aggregation: 2)>\\narray([0.596069, 0.003296])\\nC...\n",
      "    ceiling:  <xarray.Score (aggregation: 2)>\\narray([8.218406e-01, 5.871274e...\n"
     ]
    }
   ],
   "source": [
    "from candidate_models import score_model\n",
    "from candidate_models.model_commitments import brain_translated_pool\n",
    "\n",
    "identifier = 'alexnet'\n",
    "model = brain_translated_pool[identifier]\n",
    "score = score_model(model_identifier=identifier, model=model, benchmark_identifier='dicarlo.Majaj2015.IT-pls')\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A score typically comes with an estimate of the center (e.g. mean) and error (e.g. standard error of the mean).\n",
    "These values are aggregations over splits and often neuroids, and ceiled by the benchmark ceiling.\n",
    "\n",
    "Check out https://github.com/brain-score/brain-score/blob/master/examples/benchmarks.ipynb for more details."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
